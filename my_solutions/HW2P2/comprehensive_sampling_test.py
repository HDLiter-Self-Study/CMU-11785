#!/usr/bin/env python3
"""
ç»¼åˆé‡‡æ ·æµ‹è¯•è„šæœ¬
æ”¯æŒstrategyè¦†ç›–ï¼Œæµ‹è¯•æ‰€æœ‰ç²’åº¦çº§åˆ«çš„å‚æ•°é‡‡æ ·ï¼Œå¹¶ä¿å­˜ç»“æœåˆ°JSON
"""

import sys
from pathlib import Path

# Add the src directory to the Python path
project_root = Path(__file__).resolve().parent
src_path = project_root / "src"
sys.path.insert(0, str(src_path))

import optuna
from src.sampling.sampler import SearchSpaceSampler
import json
from datetime import datetime
from collections import defaultdict
import argparse


def test_granularity_sampling(strategy_overrides=None, num_samples=5, output_file=None, categories=None, silent=False):
    """
    æµ‹è¯•ä¸åŒç²’åº¦çº§åˆ«çš„å‚æ•°é‡‡æ ·

    Args:
        strategy_overrides: Hydra overrideåˆ—è¡¨ï¼Œç”¨äºå¼ºåˆ¶ç‰¹å®šstrategy
        num_samples: é‡‡æ ·æ¬¡æ•°
        output_file: è¾“å‡ºæ–‡ä»¶å
        categories: è¦é‡‡æ ·çš„æœç´¢ç©ºé—´ç±»åˆ«åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºé‡‡æ ·æ‰€æœ‰ç±»åˆ«
        silent: If True, suppress all log output from the sampler.
    """
    if not silent:
        print("ğŸš€ å¼€å§‹ç»¼åˆé‡‡æ ·æµ‹è¯•")
        print("=" * 60)

    # åˆ›å»ºé‡‡æ ·å™¨
    try:
        if strategy_overrides:
            if not silent:
                print(f"ğŸ“‹ ä½¿ç”¨Strategyè¦†ç›–:")
                for override in strategy_overrides:
                    print(f"   {override}")
            sampler = SearchSpaceSampler(overrides=strategy_overrides, silent=silent)
        else:
            sampler = SearchSpaceSampler(silent=silent)
        if not silent:
            print("âœ… é‡‡æ ·å™¨åˆ›å»ºæˆåŠŸ")

        # ç¡®å®šè¦é‡‡æ ·çš„ç±»åˆ«
        if categories is None:
            categories = sampler.search_space_categories

        if not silent:
            print(f"ğŸ“Š å°†é‡‡æ ·çš„æœç´¢ç©ºé—´ç±»åˆ«: {categories}")

    except Exception as e:
        print(f"âŒ é‡‡æ ·å™¨åˆ›å»ºå¤±è´¥: {e}")
        return None

    # æ”¶é›†é‡‡æ ·ç»“æœ
    results = {
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "num_samples": num_samples,
            "strategy_overrides": strategy_overrides or [],
            "sampled_categories": categories,
            "test_type": "comprehensive_granularity_sampling",
        },
        "samples": [],
    }

    # ç»Ÿè®¡ä¿¡æ¯
    granularity_stats = defaultdict(int)
    architecture_stats = defaultdict(int)
    stage_param_stats = defaultdict(int)
    block_stage_param_stats = defaultdict(int)

    if not silent:
        print(f"\nğŸ“Š å¼€å§‹é‡‡æ · (å…±{num_samples}æ¬¡)...")

    for i in range(num_samples):
        try:
            study = optuna.create_study(storage="sqlite:///:memory:", study_name=f"trial_{i}", direction="maximize")
            trial = study.ask()

            # è¿›è¡Œé‡‡æ ·
            result = sampler.sample_all_params(trial, categories)
            flat_params = result["flat"]
            hierarchical_params = result["hierarchical"]

            # åˆ†æé‡‡æ ·ç»“æœ
            arch_params = flat_params.get("architectures", {})
            arch_type = arch_params.get("architecture_type")
            activation_gran = arch_params.get(f"{arch_type}_activation_granularity") if arch_type else None
            norm_gran = arch_params.get(f"{arch_type}_norm_granularity") if arch_type else None
            block_type_gran = arch_params.get(f"{arch_type}_block_type_granularity") if arch_type else None
            num_stages = arch_params.get("num_stages")

            # è¯†åˆ«ä¸åŒç±»å‹çš„å‚æ•°ï¼ˆä»æ‰€æœ‰ç±»åˆ«ä¸­ï¼‰
            stage_params = []
            block_stage_params = []
            all_flat_params = {}

            # åˆå¹¶æ‰€æœ‰ç±»åˆ«çš„æ‰å¹³å‚æ•°
            for category, category_params in flat_params.items():
                if isinstance(category_params, dict):
                    for param_name, param_value in category_params.items():
                        all_flat_params[f"{category}.{param_name}"] = param_value

                    # åœ¨æ¶æ„å‚æ•°ä¸­æŸ¥æ‰¾stageå’Œblock_stageå‚æ•°
                    if category == "architectures":
                        for param_name in category_params.keys():
                            if "_stage_" in param_name and "_of_" in param_name:
                                if any(
                                    block_type in param_name
                                    for block_type in ["basic", "bottleneck", "inverted_bottleneck"]
                                ):
                                    block_stage_params.append(param_name)
                                else:
                                    stage_params.append(param_name)

            # æ„å»ºæ ·æœ¬è®°å½•
            sample_record = {
                "sample_id": i + 1,
                "trial_number": trial.number,
                "architecture_type": arch_type,
                "num_stages": num_stages,
                "granularities": {
                    "activation": activation_gran,
                    "normalization": norm_gran,
                    "block_type": block_type_gran,
                },
                "parameter_counts": {
                    "total_flat_params": len(all_flat_params),
                    "categories_sampled": len(flat_params),
                    "stage_params": len(stage_params),
                    "block_stage_params": len(block_stage_params),
                },
                "category_param_counts": {
                    category: len(params) if isinstance(params, dict) else 1 for category, params in flat_params.items()
                },
                "stage_parameters": stage_params,
                "block_stage_parameters": block_stage_params,
                "flat": flat_params,
                "hierarchical": hierarchical_params,
            }

            results["samples"].append(sample_record)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            granularity_key = f"{activation_gran}|{norm_gran}|{block_type_gran}"
            granularity_stats[granularity_key] += 1
            architecture_stats[arch_type] += 1
            stage_param_stats[len(stage_params)] += 1
            block_stage_param_stats[len(block_stage_params)] += 1

            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            if not silent:
                category_summary = ", ".join(
                    [f"{cat}:{len(params) if isinstance(params, dict) else 1}" for cat, params in flat_params.items()]
                )
                arch_info = f"{arch_type}" if arch_type else "æ— æ¶æ„"
                granularity_info = f"ç²’åº¦({activation_gran},{norm_gran},{block_type_gran})" if arch_type else ""

                print(
                    f"   æ ·æœ¬#{i+1}: {arch_info}, {granularity_info}, "
                    f"ç±»åˆ«({category_summary}), Stage:{len(stage_params)}, Block_Stage:{len(block_stage_params)}"
                )

        except Exception as e:
            print(f"   âŒ æ ·æœ¬#{i+1}é‡‡æ ·å¤±è´¥: {e}")
            # Optionally log the full traceback for debugging
            # import traceback
            # traceback.print_exc()
            continue

    # æ·»åŠ ç»Ÿè®¡æ‘˜è¦
    category_stats = defaultdict(int)
    for sample in results["samples"]:
        for category in sample["category_param_counts"]:
            category_stats[category] += 1

    results["statistics"] = {
        "granularity_combinations": dict(granularity_stats),
        "architecture_distribution": dict(architecture_stats),
        "stage_param_distribution": dict(stage_param_stats),
        "block_stage_param_distribution": dict(block_stage_param_stats),
        "category_distribution": dict(category_stats),
    }

    # ä¿å­˜ç»“æœ
    if not output_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"sampling_results_{timestamp}.json"

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        if not silent:
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
    if not silent:
        print(f"\nğŸ“ˆ é‡‡æ ·ç»Ÿè®¡æ‘˜è¦:")
        print(f"   æˆåŠŸé‡‡æ ·: {len(results['samples'])}/{num_samples}")
        print(f"   é‡‡æ ·ç±»åˆ«: {list(category_stats.keys())}")
        print(f"   ç±»åˆ«åˆ†å¸ƒ: {dict(category_stats)}")

        if architecture_stats:
            print(f"   æ¶æ„åˆ†å¸ƒ: {dict(architecture_stats)}")
            print(f"   ç²’åº¦ç»„åˆåˆ†å¸ƒ:")
            for combo, count in granularity_stats.items():
                if combo != "None|None|None":  # è·³è¿‡æ— æ¶æ„çš„æƒ…å†µ
                    activation, norm, block_type = combo.split("|")
                    print(f"     æ¿€æ´»:{activation}, å½’ä¸€åŒ–:{norm}, å—ç±»å‹:{block_type} â†’ {count}æ¬¡")

        if block_stage_param_stats and any(count > 0 for count in block_stage_param_stats.values()):
            print(f"   Block_Stageå‚æ•°åˆ†å¸ƒ: {dict(block_stage_param_stats)}")

    return results


def test_forced_scenarios(silent=False):
    """æµ‹è¯•å¼ºåˆ¶åœºæ™¯"""
    if not silent:
        print("\n\nğŸ¯ å¼ºåˆ¶åœºæ™¯æµ‹è¯•")
        print("=" * 40)

    # å®šä¹‰ä¸åŒçš„å¼ºåˆ¶åœºæ™¯
    scenarios = [
        {
            "name": "å¼ºåˆ¶Block_Stageæ¿€æ´»å‡½æ•°",
            "overrides": [
                "++search_spaces.architectures.strategy_level=custom",
                "+search_spaces.architectures.activation_params.selection.choices.custom=[block_stage]",
            ],
            "samples": 3,
        },
        {
            "name": "å¼ºåˆ¶Stageçº§å‚æ•°",
            "overrides": [
                "++search_spaces.architectures.strategy_level=custom",
                "+search_spaces.architectures.activation_params.selection.choices.custom=[stage]",
                "+search_spaces.architectures.normalization_params.selection.choices.custom=[stage]",
            ],
            "samples": 3,
        },
        {
            "name": "å¼ºåˆ¶ResNetæ¶æ„",
            "overrides": [
                "++search_spaces.architectures.strategy_level=custom",
                "+search_spaces.architectures.architecture_selection.selection.choices.custom=[resnet]",
            ],
            "samples": 3,
        },
        {
            "name": "å¼ºåˆ¶ConvNeXtæ¶æ„",
            "overrides": [
                "++search_spaces.architectures.strategy_level=custom",
                "+search_spaces.architectures.architecture_selection.selection.choices.custom=[convnext]",
            ],
            "samples": 3,
        },
    ]

    all_scenario_results = {}

    for scenario in scenarios:
        if not silent:
            print(f"\nğŸ§ª æµ‹è¯•åœºæ™¯: {scenario['name']}")

        result = test_granularity_sampling(
            strategy_overrides=scenario["overrides"],
            num_samples=scenario["samples"],
            output_file=f"scenario_{scenario['name'].replace(' ', '_').lower()}.json",
            silent=silent,  # Pass silent flag down
        )

        if result:
            all_scenario_results[scenario["name"]] = result
            if not silent:
                print(f"âœ… åœºæ™¯æµ‹è¯•å®Œæˆ")
        else:
            if not silent:
                print(f"âŒ åœºæ™¯æµ‹è¯•å¤±è´¥")

    return all_scenario_results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç»¼åˆé‡‡æ ·æµ‹è¯•è„šæœ¬")
    parser.add_argument("--samples", type=int, default=10, help="é‡‡æ ·æ¬¡æ•° (é»˜è®¤: 10)")
    parser.add_argument("--output", type=str, help="è¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("--override", action="append", help="Hydraè¦†ç›–å‚æ•° (å¯é‡å¤ä½¿ç”¨)")
    parser.add_argument("--scenarios", action="store_true", help="è¿è¡Œå¼ºåˆ¶åœºæ™¯æµ‹è¯•")
    parser.add_argument("--basic-only", action="store_true", help="åªè¿è¡ŒåŸºç¡€éšæœºé‡‡æ ·")
    parser.add_argument("--silent", action="store_true", help="Run in silent mode with no log output")
    parser.add_argument(
        "--categories",
        nargs="+",
        help="æŒ‡å®šè¦é‡‡æ ·çš„æœç´¢ç©ºé—´ç±»åˆ« (é»˜è®¤: æ‰€æœ‰ç±»åˆ«)",
        choices=["architectures", "training", "losses", "augmentation", "data_sampling", "label_mixing"],
    )

    args = parser.parse_args()

    if not args.silent:
        print("ğŸŒŸ ç»¼åˆé‡‡æ ·æµ‹è¯•è„šæœ¬")
        print("=" * 60)

    # åŸºç¡€éšæœºé‡‡æ ·æµ‹è¯•
    if not args.scenarios or not args.basic_only:
        if not args.silent:
            print("\nğŸ“‹ åŸºç¡€éšæœºé‡‡æ ·æµ‹è¯•")
        basic_result = test_granularity_sampling(
            strategy_overrides=args.override,
            num_samples=args.samples,
            output_file=args.output,
            categories=args.categories,
            silent=args.silent,
        )

    # å¼ºåˆ¶åœºæ™¯æµ‹è¯•
    if args.scenarios and not args.basic_only:
        scenario_results = test_forced_scenarios(silent=args.silent)

        # ä¿å­˜æ‰€æœ‰åœºæ™¯ç»“æœçš„æ±‡æ€»
        summary_file = "all_scenarios_summary.json"
        try:
            with open(summary_file, "w", encoding="utf-8") as f:
                json.dump(scenario_results, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ æ‰€æœ‰åœºæ™¯æ±‡æ€»å·²ä¿å­˜åˆ°: {summary_file}")
        except Exception as e:
            print(f"\nâŒ ä¿å­˜åœºæ™¯æ±‡æ€»å¤±è´¥: {e}")

    print("\nğŸ‰ ç»¼åˆæµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
