# =============================================================================
# UNIFIED EXPERIMENT CONFIGURATION
# Example: Face Recognition with Custom Deep Architecture Search
# =============================================================================
experiment_name: "face_recognition_deep_search_v1"
description: "Face recognition experiment with custom deep ResNet search and aggressive augmentation"
author: "Research Team"
created_date: "2025-08-02"

# =============================================================================
# STRATEGY LEVELS (控制各模块的搜索空间大小)
# =============================================================================
strategy_levels:
  augmentation: "comprehensive"      # 使用全面的增强策略
  label_mixing: "robust"            # 中等程度的标签混合
  data_sampling: "basic"            # 简单的数据采样
  architectures: "custom"           # 自定义架构搜索空间
  training: "custom"                # 自定义训练参数搜索

# =============================================================================
# FIXED PARAMETERS (不参与搜索的固定值)
# =============================================================================
fixed_params:
  # 训练固定参数
  epochs: 120
  save_frequency: 10
  eval_frequency: 5
  early_stopping_patience: 15
  
  # 数据固定参数
  num_workers: 8
  pin_memory: true
  persistent_workers: true
  
  # 模型固定参数
  num_classes: 7000
  input_size: [224, 224]
  
  # 硬件配置
  device: "cuda"
  mixed_precision: true
  compile_model: true              # PyTorch 2.0 模型编译

# =============================================================================
# PARAMETER OVERRIDES (覆盖默认搜索空间)
# =============================================================================
parameter_overrides:
  # ==================== 增强参数自定义 ====================
  "augmentation.spatial_augmentation_strategy":
    choices: ["random_erasing", "gridmask", "random_resized_crop", "random_choice"]
    
  "augmentation.gaussian_noise_std":
    min: 0.005
    max: 0.12
    description: "Extended noise range for robustness"
    
  "augmentation.random_erasing_prob":
    min: 0.15
    max: 0.75
    
  "augmentation.gridmask_prob":
    min: 0.3
    max: 0.9
    
  # ==================== 架构参数自定义 ====================
  "architectures.architecture_type":
    choices: ["resnet", "convnext"]     # 支持两种架构对比
    
  "architectures.regnet_max_stage_depth":
    resnet:
      custom: [12, 16, 20, 24, 28]     # 支持超深ResNet
    convnext: 
      custom: [8, 12, 16, 20]          # ConvNeXt也可以更深
      
  "architectures.regnet_depth_slope":
    min: 0.008
    max: 0.15                          # 扩大深度生成范围
    
  "architectures.regnet_depth_bias":
    min: -1.0
    max: 4.0                           # 更灵活的深度偏置
    
  "architectures.regnet_num_stages":
    choices: [3, 4, 5, 6]              # 支持6阶段网络
    
  # ==================== 训练参数自定义搜索 ====================
  "training.learning_rate":
    min: 0.00003
    max: 0.015
    log_scale: true
    description: "Wide learning rate search for deep networks"
    
  "training.weight_decay":
    min: 0.00005
    max: 0.05
    log_scale: true
    
  "training.optimizer_type":
    choices: ["adamw", "sgd", "lamb", "adafactor"]
    
  "training.scheduler_type":
    choices: ["cosine", "polynomial", "exponential", "reduce_on_plateau"]
    
  # ==================== 标签混合自定义 ====================
  "label_mixing.mixup_alpha":
    min: 0.1
    max: 3.0                           # 更激进的mixup
    
  "label_mixing.cutmix_alpha":
    min: 0.3
    max: 2.5

# =============================================================================
# SEARCH SPACE EXTENSIONS (添加新的搜索参数)
# =============================================================================
extended_search_space:
  # ==================== 训练技巧参数 ====================
  "training.gradient_clip_norm":
    type: "float"
    min: 0.5
    max: 15.0
    description: "Gradient clipping norm for stable training"
    
  "training.label_smoothing":
    type: "float"
    min: 0.0
    max: 0.25
    description: "Label smoothing factor"
    
  "training.ema_decay":
    type: "float"
    min: 0.995
    max: 0.9999
    description: "Exponential moving average decay"
    
  "training.warmup_epochs":
    type: "int"
    min: 3
    max: 15
    description: "Learning rate warmup epochs"
    
  # ==================== 架构增强参数 ====================
  "architectures.se_reduction_ratio":
    type: "categorical"
    choices: [4, 8, 16, 32]
    condition: "$architecture_type == 'resnet'"
    description: "SE module reduction ratio for ResNet"
    
  "architectures.drop_path_rate":
    type: "float"
    min: 0.0
    max: 0.3
    condition: "$architecture_type == 'convnext'"
    description: "DropPath rate for ConvNeXt"
    
  "architectures.layer_scale_init":
    type: "float"
    min: 0.00001
    max: 0.1
    log_scale: true
    condition: "$architecture_type == 'convnext'"
    description: "Layer scale initialization for ConvNeXt"
    
  # ==================== 数据增强扩展 ====================
  "augmentation.cutmix_prob":
    type: "float"
    min: 0.0
    max: 0.8
    description: "Probability of applying CutMix during training"
    
  "augmentation.auto_augment_policy":
    type: "categorical"
    choices: ["none", "imagenet", "cifar10", "custom"]
    description: "AutoAugment policy selection"

# =============================================================================
# CONDITIONAL PARAMETERS (条件化参数)
# =============================================================================
conditional_params:
  # SGD特定参数
  "training.momentum":
    type: "float"
    min: 0.85
    max: 0.99
    condition: "$optimizer_type == 'sgd'"
    description: "SGD momentum"
    
  "training.nesterov":
    type: "categorical"
    choices: [true, false]
    condition: "$optimizer_type == 'sgd'"
    
  # AdamW特定参数
  "training.adam_beta1":
    type: "float"
    min: 0.85
    max: 0.95
    condition: "$optimizer_type in ['adamw', 'lamb']"
    
  "training.adam_beta2":
    type: "float"
    min: 0.95
    max: 0.999
    condition: "$optimizer_type in ['adamw', 'lamb']"

# =============================================================================
# OPTUNA SEARCH CONFIGURATION
# =============================================================================
search_config:
  # 搜索算法配置
  sampler: "TPESampler"
  sampler_params:
    n_startup_trials: 30
    n_ei_candidates: 50
    multivariate: true
    
  # 试验配置
  n_trials: 300
  timeout: 28800                     # 8小时
  
  # 早停配置
  pruner: "MedianPruner"
  pruner_params:
    n_startup_trials: 25
    n_warmup_steps: 40
    interval_steps: 5
    
  # 并行配置
  n_jobs: 4                          # 并行试验数量
  
  # 目标优化
  objectives:
    primary: "val_accuracy"          # 主要目标
    secondary: "model_efficiency"    # 次要目标（FLOPs/accuracy）
    direction: ["maximize", "maximize"]
    
  # 约束条件
  constraints:
    max_model_size_mb: 500           # 模型大小限制
    max_training_time_hours: 3       # 单次训练时间限制

# =============================================================================
# EXPERIMENT TRACKING
# =============================================================================
tracking:
  # Weights & Biases配置
  wandb:
    project: "face_recognition_deep_search"
    entity: "research_team"
    tags: ["deep_architecture", "custom_search", "face_recognition"]
    
  # 本地日志配置
  local_logging:
    log_dir: "./logs"
    save_configs: true
    save_model_checkpoints: true
    
  # 结果保存
  results:
    save_top_k: 10                   # 保存top-10模型
    save_final_ensemble: true        # 保存集成模型

# =============================================================================
# RESOURCE MANAGEMENT
# =============================================================================
resources:
  # GPU配置
  gpu_memory_fraction: 0.9
  allow_memory_growth: true
  
  # 分布式训练（如果需要）
  distributed:
    enabled: false
    backend: "nccl"
    world_size: 1
    
  # 数据加载优化
  dataloader:
    prefetch_factor: 4
    multiprocessing_context: "spawn"

# =============================================================================
# VALIDATION AND TESTING
# =============================================================================
validation:
  # 验证策略
  validation_split: 0.15
  stratified_split: true
  
  # 测试配置
  test_time_augmentation: true
  tta_crops: 10
  
  # 评估指标
  metrics:
    - "accuracy"
    - "top5_accuracy" 
    - "f1_score"
    - "precision"
    - "recall"
    - "confusion_matrix"

# =============================================================================
# NOTES AND COMMENTS
# =============================================================================
experiment_notes: |
  This experiment configuration demonstrates:
  
  1. **Deep Architecture Search**: Custom ResNet up to 28 blocks per stage
  2. **Multi-Architecture Comparison**: ResNet vs ConvNeXt with architecture-specific parameters
  3. **Aggressive Augmentation**: Comprehensive spatial and noise augmentation
  4. **Advanced Training**: EMA, label smoothing, gradient clipping, warmup
  5. **Conditional Parameters**: Optimizer-specific parameter tuning
  6. **Resource Management**: GPU memory optimization and parallel search
  7. **Comprehensive Tracking**: Both local and cloud experiment tracking
  
  Expected to find optimal deep architectures for face recognition with
  robust augmentation strategies.

version: "1.0"
schema_version: "unified_config_v1"
